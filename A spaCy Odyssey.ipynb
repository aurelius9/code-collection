{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Model Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Text Categorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://spacy.io/api/textcategorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#typically a couple hundred examples are required for accurate results \n",
    "train_data = [\n",
    "    (u\"Malta\", {'cats': {'EUROPEAN': 1.0, 'NA': 0.0}}),\n",
    "    (u\"Crete\", {'cats': {'EUROPEAN': 1.0, 'NA': 0.0}}),\n",
    "    (u\"USA\", {'cats': {'EUROPEAN': 0.0, 'NA': 1.0}}),\n",
    "    (u\"British\", {'cats': {'EUROPEAN': 1.0, 'NA': 0.0}}),\n",
    "    (u\"Brazil\", {'cats': {'EUROPEAN': 0.0, 'NA': 1.0}}),\n",
    "    (u\"Canadian\", {'cats': {'EUROPEAN': 0.0, 'NA': 1.0}}),\n",
    "    (u\"Sweden\", {'cats': {'EUROPEAN': 1.0, 'NA': 0.0}})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EUROPEAN': 0.8027938604354858, 'NA': 0.13836686313152313}\n",
      "{'EUROPEAN': 0.5758070945739746, 'NA': 0.6145948171615601}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "#create blank nlp model in english\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "#initialize nlp pipeline\n",
    "textcat = nlp.create_pipe('textcat')\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "#add custom categories\n",
    "textcat.add_label('EUROPEAN')\n",
    "textcat.add_label('NA')\n",
    "\n",
    "#begin training\n",
    "nlp.vocab.vectors.name = 'spacy_pretrained_vectors'\n",
    "optimizer = nlp.begin_training()\n",
    "for itn in range(10):\n",
    "    for doc, gold in train_data:\n",
    "        nlp.update([doc], [gold], sgd=optimizer)\n",
    "doc = nlp(u'United States')\n",
    "print(doc.cats)\n",
    "doc = nlp(u'Britain')\n",
    "print(doc.cats)\n",
    "\n",
    "#output model to be used later \n",
    "output_dir = r'file path'\n",
    "output_dir = Path(output_dir) \n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "output_dir = r'file path'\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp = spacy.load(output_dir)\n",
    "\n",
    "#test the model\n",
    "doc = nlp(u'Italy')\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Entity Recognition & Update Pre-Existing Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# new entity label\n",
    "LABEL = 'ROLL_TIDE'\n",
    "\n",
    "TRAIN_DATA = [\n",
    "    (\"Feb\", {\n",
    "        'entities': [(0, 2, 'DATE')]\n",
    "    }),\n",
    "\n",
    "    (\"15/16E\", {\n",
    "        'entities': [(0, 5, 'DATE')]\n",
    "    }),\n",
    "\n",
    "    (\"Apr 20\", {\n",
    "        'entities': [(0, 6, 'DATE')]\n",
    "    }),\n",
    "   \n",
    "    (\"Nick Saban\", {\n",
    "        'entities': [(0, 10, 'ROLL_TIDE')]\n",
    "    }),\n",
    "    (\"Crimson Tide\", {\n",
    "        'entities': [(0, 12, 'ROLL_TIDE')]\n",
    "    }),\n",
    "\n",
    "    (\"Big Al\", {\n",
    "        'entities': [(0, 6, 'ROLL_TIDE')]\n",
    "    }),\n",
    "    (\"Tua 4 Heisman\", {\n",
    "        'entities': [(0, 13, 'ROLL_TIDE')]\n",
    "    })]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=None, new_model_name='ROLL_TIDE', output_dir=r'file_path', n_iter=100):\n",
    "    \n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    if model is not None:\n",
    "        #loads pre-trained spacy en model - other options available here: https://spacy.io/usage/models\n",
    "        #nlp = spacy.load('en_core_web_sm') ~ set model in function to the string value\n",
    "        \n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:        \n",
    "        # create blank Language class\n",
    "        nlp = spacy.blank('en') \n",
    "        print(\"Created'en' model\")\n",
    "        \n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "    \n",
    "    # add new entity label to entity recognizer\n",
    "    ner.add_label(LABEL)   \n",
    "    \n",
    "    #prepares model for training\n",
    "    if model is None:\n",
    "        nlp.vocab.vectors.name = 'spacy_pretrained_vectors'\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        # Note that 'begin_training' initializes the models, so it'll zero out\n",
    "        # existing entity types.\n",
    "        optimizer = nlp.entity.create_optimizer()\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update([text], [annotations], sgd=optimizer, drop=0.35,\n",
    "                           losses=losses)\n",
    "            print(losses)\n",
    "\n",
    "    # test the trained model\n",
    "    test_text = \"Tua will win the heisman for Nick Saban\"\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label_, ent.text)\n",
    "        \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "{'ner': 15.334686279296875}\n",
      "{'ner': 12.651902079582477}\n",
      "{'ner': 7.685541325721033}\n",
      "{'ner': 9.873688644726956}\n",
      "{'ner': 4.876519405549766}\n",
      "{'ner': 8.090691986142303}\n",
      "{'ner': 3.625201584482973}\n",
      "{'ner': 3.729167474906981}\n",
      "{'ner': 1.998796757055175}\n",
      "{'ner': 3.689720597178588}\n",
      "{'ner': 3.245556431308616}\n",
      "{'ner': 5.1487211471227035}\n",
      "{'ner': 2.5634499418059926}\n",
      "{'ner': 1.8287298862904928}\n",
      "{'ner': 1.5394464414217934}\n",
      "{'ner': 1.926327181039602}\n",
      "{'ner': 5.9955483556850275}\n",
      "{'ner': 1.4431897458790681}\n",
      "{'ner': 1.4667095744657224}\n",
      "{'ner': 2.874917328417063}\n",
      "{'ner': 0.5000000151990281}\n",
      "{'ner': 6.506236419112741e-06}\n",
      "{'ner': 1.4483597933900536}\n",
      "{'ner': 3.3520205829331924}\n",
      "{'ner': 0.9349699296397354}\n",
      "{'ner': 4.331620216369806}\n",
      "{'ner': 0.9444444180519406}\n",
      "{'ner': 1.8620462580376957}\n",
      "{'ner': 0.9375544141773794}\n",
      "{'ner': 3.269705060213063}\n",
      "{'ner': 2.876355238258844}\n",
      "{'ner': 2.862998170264444}\n",
      "{'ner': 2.78917238676702}\n",
      "{'ner': 1.1039174944177994}\n",
      "{'ner': 0.9182705085061468}\n",
      "{'ner': 1.433335269949355}\n",
      "{'ner': 1.8411764675621896}\n",
      "{'ner': 1.7735666626704245}\n",
      "{'ner': 1.866336249661186}\n",
      "{'ner': 1.9434332950155215}\n",
      "{'ner': 0.9333370199224844}\n",
      "{'ner': 2.482586741450172}\n",
      "{'ner': 2.7707305587829874}\n",
      "{'ner': 1.444445363134799}\n",
      "{'ner': 2.3704453713188247}\n",
      "{'ner': 2.373019523967354}\n",
      "{'ner': 1.4285714117888668}\n",
      "{'ner': 5.937129691245863e-07}\n",
      "{'ner': 2.787839363890059}\n",
      "{'ner': 1.8541835568016218}\n",
      "{'ner': 9.381958024833956e-10}\n",
      "{'ner': 8.402764671566754e-09}\n",
      "{'ner': 3.6861198130095554}\n",
      "{'ner': 0.9285799862905573}\n",
      "{'ner': 1.428573548793863}\n",
      "{'ner': 3.9613240659237023}\n",
      "{'ner': 2.861117940716301}\n",
      "{'ner': 1.870834589903711}\n",
      "{'ner': 2.7607447518845487}\n",
      "{'ner': 1.9285718202751543}\n",
      "{'ner': 1.4411765647079684}\n",
      "{'ner': 0.008449882340957686}\n",
      "{'ner': 0.9555851819534213}\n",
      "{'ner': 0.9230768681325622}\n",
      "{'ner': 0.9343966842749895}\n",
      "{'ner': 1.0}\n",
      "{'ner': 1.0000000000000038}\n",
      "{'ner': 1.4000000357627869}\n",
      "{'ner': 1.4166669249534616}\n",
      "{'ner': 8.337284660728944e-08}\n",
      "{'ner': 0.9285729534973644}\n",
      "{'ner': 3.234921097755435}\n",
      "{'ner': 2.3819465041581784}\n",
      "{'ner': 3.7418680148888654}\n",
      "{'ner': 0.956521689892324}\n",
      "{'ner': 2.0915620326998097}\n",
      "{'ner': 1.9166665673320082}\n",
      "{'ner': 1.8660752177238482}\n",
      "{'ner': 1.4247689247478272}\n",
      "{'ner': 2.8152789256455897}\n",
      "{'ner': 2.342425465583817}\n",
      "{'ner': 2.3452380299575686}\n",
      "{'ner': 3.2551059790424413}\n",
      "{'ner': 3.299936473370027}\n",
      "{'ner': 0.8888888622384399}\n",
      "{'ner': 1.866666737805466}\n",
      "{'ner': 1.8037747144699097}\n",
      "{'ner': 5.166602058590381e-12}\n",
      "{'ner': 1.8516483902935312}\n",
      "{'ner': 0.9230768680572515}\n",
      "{'ner': 1.9285714626522474}\n",
      "{'ner': 2.7683148385010297}\n",
      "{'ner': 1.8321677446367157}\n",
      "{'ner': 2.367521501110161}\n",
      "{'ner': 1.9333333373070745}\n",
      "{'ner': 3.2986112236976624}\n",
      "{'ner': 0.8999999761581445}\n",
      "{'ner': 2.7777779698371887}\n",
      "{'ner': 0.9565217494967243}\n",
      "{'ner': 8.130146173299149e-13}\n",
      "Entities in 'Tua will win the heisman for Nick Saban'\n",
      "ROLL_TIDE Tua will\n",
      "ROLL_TIDE the heisman\n",
      "ROLL_TIDE for Nick\n"
     ]
    }
   ],
   "source": [
    "bama_nlp = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
